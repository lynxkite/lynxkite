
# This file contains various configurations used when launching a LynxKite instance.

# Settings in this file can be overriden using environment variables.

# Specify the directory containing your Spark installation.
export SPARK_HOME=$HOME/spark/spark-${SPARK_VERSION}

# To specify which cluster to use choose one of the following options:

# - local - for single machine installs
# - yarn - for using YARN (Hadoop v2). Please also set YARN_* settings below.

export SPARK_MASTER=local

# Specify the directory where LynxKite stores metadata about projects. The directory must be on
# the local file system. Do not forget to set up backups.
export KITE_META_DIR=$HOME/kite_meta

# Specify the directory of the data where graph data is stored. Should be on a distributed fs
# (HDFS, S3, etc) unless this is a local setup. Please note that giving the full
# URI (e.g., file:/...) is mandatory.
export KITE_DATA_DIR=file:$HOME/kite_data/

# LynxKite can use a faster ephemeral file system for data storage, with reading from the main
# file system specified by KITE_DATA_DIR as a fallback. The primary use case for this is using
# SSD-backed HDFS on EC2 while using S3 for the permanent storage.

# If KITE_EPHEMERAL_DATA_DIR is set, all data writes go to this directory. KITE_DATA_DIR will be
# used only for uploaded files.
# export KITE_EPHEMERAL_DATA_DIR=

# Optionally set the configuration file to specify what file paths users are allowed to access using
# what prefixes. Use kite_x.y.z/conf/prefix_definitions_template.txt as a template when creating
# your custom prefix configuration file. Make sure you put the config file to a LynxKite version
# independent location (not inside the kite_x.y.z directory, e.g. $HOME/kite_conf). Then set
# KITE_PREFIX_DEFINITIONS to point to your newly created config file (e.g. the recommended
# $HOME/kite_conf/prefix_definitions.txt).
export KITE_PREFIX_DEFINITIONS=

# Normally, LynxKite can only access the file system via its prefix mechanism,
# that is, using either the DATA$ prefix (as in DATA$/dir/file.csv) or any other
# prefixes set up in a prefix definition file. This behavior can be changed by
# setting KITE_ALLOW_NON_PREFIXED_PATHS to true: then it becomes possible to
# specify any valid paths such as file:/home/user/kite_data/dir/data.csv
# or s3n://awskey:awspassword@somedir/somefile. Be careful: all LynxKite users will
# be able to read and write local and cluster files with the credentials of the LynxKite process.
# Only allow this in restricted environments.
export KITE_ALLOW_NON_PREFIXED_PATHS=false

# Specify the PID file for LynxKite servers.
export KITE_PID_FILE=$HOME/kite.pid

# When set, each action performed by the lynxkite script (start,stop,restart, etc.) is logged to
# this file.
export KITE_SCRIPT_LOGS=$HOME/lynxkite.log

# Specify the user registry file for LynxKite servers.
export KITE_USERS_FILE=$HOME/kite_users

# Specify the YARN configuration directory. It is needed if you want to run against YARN.
# export YARN_CONF_DIR=/etc/hadoop/...

# By default, LynxKite specifies 15% of executor memory to be the amount allocated for overhead
# in YARN executor containers. You can set a higher value if YARN is killing your executors for
# exceeding size, but the executors themselves are not reporting out of memory errors.
# export YARN_EXECUTOR_MEMORY_OVERHEAD_MB=4000

# YARN offers the possibility of using resource pools. You can specify an existing resource pool and
# allocate LynxKite to it.
# export RESOURCE_POOL=

# Specify how much memory is available for LynxKite on a single worker machine.
# Ignored for local setups, use KITE_MASTER_MEMORY_MB for that case.
export EXECUTOR_MEMORY=1g

# Specify the number of executors. For standalone cluster it defaults to as many as possible.
# For a YARN setup, this options is mandatory.
# export NUM_EXECUTORS=5

# Specify the number of cores per executor LynxKite should use. For local mode, you
# can set it to * to use as many cores as available.
export NUM_CORES_PER_EXECUTOR=4

# Specify how much memory is available for LynxKite on the master machine in megabytes.
# For local setups this also determines executor memory and EXECUTOR_MEMORY is
# ignored in that case.
export KITE_MASTER_MEMORY_MB=1024

# Specify the port for the LynxKite HTTP server to listen on. Must be >=1000.
export KITE_HTTP_PORT=2200

# By default, LynxKite can only be accessed from localhost for security reasons. (That is,
# address 127.0.0.1). Uncomment the following line if LynxKite should be accessible
# from other IP addresses as well.
# export KITE_HTTP_ADDRESS=0.0.0.0

# Specify the HTTP port for the watchdog. If this is set, the startup script will start a watchdog
# as well which will automatically restart the LynxKite server if it detects any problem.
# export KITE_WATCHDOG_PORT=2202

# Uncomment this to start an internal watchdog thread inside LynxKite's
# driver JVM. This watchdog will kill LynxKite if health checks are
# failing continuously for the given amount of time.
# export KITE_INTERNAL_WATCHDOG_TIMEOUT_SECONDS=1200

# The LynxKite local temp directory is a local path that exists on all workers and the master and will
# be used for storing temporary Spark/Hadoop files. This directory can potentially use a lot of
# space, so if you have a small root filesystem and an extra large drive mounted somewhere then you
# need to point this to somewhere on the large drive. On the other hand performance of this drive has
# a significant effect on overall speed, so using an SSD is a nice option here.
export KITE_LOCAL_TMP=/tmp

# Configure the directory LynxKite uses for logging. Defaults to logs under the LynxKite
# installation directory if not specified.
# export KITE_LOG_DIR=

# The LynxKite extra JARS is a colon (:) delimited list of JAR files that should be loaded on the
# LynxKite CLASSPATH. (It will be loaded on the master and distributed to the workers.)

# - Some wildcards are supported, you can use /dir/*, but you cannot use /dir/*.jar.
# - Filenames have to be absolute paths.

# One typical use case is to configure additional JDBC drivers. To do that, all you need to do is to
# add the jar file here.
export KITE_EXTRA_JARS=

# You can enable an interactive Scala interpreter able to access LynxKite internals by using
# the below exports. You can access the interpreter by SSHing from the host running LynxKite as:
# ssh ${KITE_AMMONITE_USER}@localhost -p ${KITE_AMMONITE_PORT}
# and use KITE_AMMONITE_PASSWD as password.

# If you do this and do not trust all users who can SSH into this machine (the typical case!)
# then make sure to modify the file system permissions of .kiterc to be only readable by the
# user running LynxKite and change the password below.
# export KITE_AMMONITE_PORT=2203
# export KITE_AMMONITE_USER=lynx
# export KITE_AMMONITE_PASSWD=kite

# Options needed if you want to use authentication and HTTPS.

# Just use the following configurations with default values for a simple, fake certificate setup.

# ===========================================================
# Application secret used by Play! framework for various tasks, such as signing cookies and
# encryption. Setting this to <random> will regenerate a secret key at each restart.
# More details can be found
# here (https://playframework.com/documentation/latest/ApplicationSecret).
# export KITE_APPLICATION_SECRET='<random>'

# Specify the port for the LynxKite HTTPS server to listen on. Must be >=1000.
# export KITE_HTTPS_PORT=2201

# By default if you turn on HTTPS, only logged-in users will be able to access the LynxKite UI.
# If you want users to be able to have read-only access without logging in, set
# KITE_ACCESS_WITHOUT_LOGIN to yes. Whether these users are restricted to using wizards
# is controlled by the second setting.
# export KITE_ACCESS_WITHOUT_LOGIN=yes
# export KITE_WIZARD_ONLY_WITHOUT_LOGIN=yes

# Set the keystore file and password with the HTTPS keys. Use the default values for a fake HTTPS
# certificate. If you have your own intranet CA or a wildcard certificate, you can generate a
# certificate for LynxKite that the browsers can validate. Follow the instructions at
# Apache Tomcat (http://tomcat.apache.org/tomcat-6.0-doc/ssl-howto.html) for creating a keystore file.
# export KITE_HTTPS_KEYSTORE=${KITE_DEPLOYMENT_CONFIG_DIR}/localhost.self-signed.cert
# export KITE_HTTPS_KEYSTORE_PWD=keystore-password
# ===========================================================

# The following settings configure Google OAuth for LynxKite.
# export KITE_GOOGLE_CLIENT_SECRET='???'
# export KITE_GOOGLE_CLIENT_ID='???.apps.googleusercontent.com'
# export KITE_GOOGLE_HOSTED_DOMAIN='example.com'
# export KITE_GOOGLE_REQUIRED_SUFFIX='@example.com'
# export KITE_GOOGLE_WIZARD_ONLY='yes'
# export KITE_GOOGLE_PUBLIC_ACCESS='yes'

# Use the following configurations to set up LDAP authentication.

# ===========================================================
# The URL of the LDAP server, e.g. ldap://localhost:389.
# export LDAP_URL=

# The authentication method, e.g. simple or DIGEST-MD5 as explained in
# the Java LDAP documentation (http://docs.oracle.com/javase/jndi/tutorial/ldap/security/index.html)
# and SASL documentation (http://docs.oracle.com/javase/jndi/tutorial/ldap/security/sasl.html).
# export LDAP_AUTHENTICATION=simple

# The template for the principal. It must contain the word <USERNAME> to be substituted with the
# username given at login, for example uid=<USERNAME>,ou=People,dc=example,dc=com or
# cn=<USERNAME>,ou=People,dc=example,dc=com. This is required so the user does not have to specify
# the full distinguished name on the web UI.
# export LDAP_PRINCIPAL_TEMPLATE=
# ===========================================================

# On a Kerberos-secured Hadoop cluster, set the KERBEROS_PRINCIPAL and KERBEROS_KEYTAB
# variables. The principal acts like a user name and the keytab file acts like a password.
# export KERBEROS_PRINCIPAL=
# export KERBEROS_KEYTAB=

# The setting KITE_MAX_ALLOWED_FILESYSTEM_LIFESPAN_MS forces LynxKite to create a
# new Hadoop Filesystem object every time KITE_MAX_ALLOWED_FILESYSTEM_LIFESPAN_MS milliseconds
# have passed. This mechanism prevents certain errors related to Hadoop delegation token expiration.
# A good value for this is half the time specified in the system's
# dfs.namenode.delegation.token.renew-interval setting. That defaults to 1 day, so our default is 12 hours.
# See this explanation (https://blog.cloudera.com/blog/2017/12/hadoop-delegation-tokens-explained)
# for details.
# export KITE_MAX_ALLOWED_FILESYSTEM_LIFESPAN_MS = $((1000*60*60*12))

# Uncomment the below lines to export LynxKite's Spark metrics into
# a Graphite-compatible monitoring system. You can use this together
# with tools/monitoring/restart_monitoring_master.sh.
# export GRAPHITE_MONITORING_HOST=$(hostname)
# export GRAPHITE_MONITORING_PORT=9109

# Specify any command line arguments for the jvm that runs the LynxKite driver.
# (e.g., EXTRA_DRIVER_OPTIONS='-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=50000'
# will run a local LynxKite in a such a mode that you can attach to it with a debugger.)
# export EXTRA_DRIVER_OPTIONS=

# Set thread stack size for thread in the executor process. By default, jvm will assign
# 1 megabyte for each thread, but that is too low for some rdd dependencies.
# The suffixes M and k can be used to specify megabytes or kilobytes respectively; e.g., 1M or 1500k.
# This setting does not have an effect in local mode.
# export EXECUTOR_THREAD_STACK_SIZE=3M

# Set thread stack size for driver threads. By default, jvm will assign 1 megabyte for each thread,
# but that is too low for some rdd dependencies. The suffixes M and k can be used to specify megabytes
# or kilobytes respectively; e.g., 1M or 1500k.
# export DRIVER_THREAD_STACK_SIZE=2M

# Maximize the number of parallel threads. LynxKite, Spark domain and Sphynx will
# all use this parameter.
# export KITE_PARALLELISM=5

# Specify the length of the protected time period in days, while the cleaner does not
# delete data files. It can be integer or double value.
# export KITE_CLEANER_MIN_AGE_DAYS=14

# Anonymous data collection is opt-in by default. This setting can be used to force it on
# or off on an instance. Accepted values are: optional, always, never
# export KITE_DATA_COLLECTION=optional

# Specify where Sphynx (the single-node server) is running and where the certificate can be found.
# If any of these is unset, no Sphynx server is assumed.
export SPHYNX_HOST=localhost
export SPHYNX_PORT=50051
export SPHYNX_CERT_DIR=$HOME/sphynx_cert
# Specify the PID file for Sphynx.
export SPHYNX_PID_FILE=$HOME/sphynx.pid
# Specify the directory where Sphynx stores graph data.
export ORDERED_SPHYNX_DATA_DIR=$HOME/ordered_sphynx_data
# Specify the directory where Sphynx stores graph data using vertex ids from the Spark world.
export UNORDERED_SPHYNX_DATA_DIR=$HOME/unordered_sphynx_data

# Unrestricted Python in LynxKite is a very powerful tool. Since Python execution has full access
# to the network and file-system, it must be explicitly enabled by the administrator.
# export KITE_ALLOW_PYTHON=yes

# A simple chroot-based sandbox for executing users' Python code can improve security in a multi-user
# environment. To be able to mount directories as read-only, this requires running LynxKite as root.
# If it's running in a Docker container, that container must be started with the --privileged flag.
# export SPHYNX_CHROOT_PYTHON=yes

# Sphynx can keep entities in memory for high-performance computation. This setting
# configures how much memory to allocate for this purpose.
export SPHYNX_CACHED_ENTITIES_MAX_MEM_MB=2000
