
# This file contains various configurations used when launching a LynxKite instance.

# Specify this to be the instance (client) where the program is run. E.g., MyCLient.
export KITE_INSTANCE=

# Specify the directory containing your Spark installation.
export SPARK_HOME=$HOME/spark-${SPARK_VERSION}

# To specify which cluster to use choose one of the following options:

# - local - for single machine installs
# - yarn - for using YARN (Hadoop v2). Please also set YARN_* settings below.

export SPARK_MASTER=local

# Specify the directory where LynxKite stores metadata about projects. The directory must be on
# the local file system. Do not forget to set up backups.
export KITE_META_DIR=$HOME/kite_meta

# Specify the directory of the data where graph data is stored. Should be on a distributed fs
# (HDFS, S3, etc) unless this is a local setup. Please note that giving the full
# URI (e.g., file:/...) is mandatory.
export KITE_DATA_DIR=file:$HOME/kite_data/

# LynxKite can use a faster ephemeral file system for data storage, with reading from the main
# file system specified by KITE_DATA_DIR as a fallback. The primary use case for this is using
# SSD-backed HDFS on EC2 while using S3 for the permanent storage.

# If KITE_EPHEMERAL_DATA_DIR is set, all data writes go to this directory. KITE_DATA_DIR will be
# used only for uploaded files.
# export KITE_EPHEMERAL_DATA_DIR=

# Optionally set the configuration file to specify what file paths users are allowed to access using
# what prefixes. Use kite_x.y.z/conf/prefix_definitions_template.txt as a template when creating
# your custom prefix configuration file. Make sure you put the config file to a LynxKite version
# independent location (not inside the kite_x.y.z directory, e.g. $HOME/kite_conf). Then set
# KITE_PREFIX_DEFINITIONS to point to your newly created config file (e.g. the recommended
# $HOME/kite_conf/prefix_definitions.txt).
export KITE_PREFIX_DEFINITIONS=

# Specify the PID file for LynxKite servers.
export KITE_PID_FILE=$HOME/kite.pid

# When set, each action performed by the biggraph script (start,stop,restart, etc.) is logged to
# this file.
export KITE_SCRIPT_LOGS=$HOME/biggraph.log

# Specify the user registry file for LynxKite servers.
export KITE_USERS_FILE=$HOME/kite_users

# Specify the YARN configuration directory. It is needed if you want to run against YARN.
# export YARN_CONF_DIR=/etc/hadoop/...

# By default, LynxKite specifies 15% of executor memory to be the amount allocated for overhead
# in YARN executor containers. You can set a higher value if YARN is killing your executors for
# exceeding size, but the executors themselves are not reporting out of memory errors.
# export YARN_EXECUTOR_MEMORY_OVERHEAD_MB=4000

# YARN offers the possibility of using resource pools. You can specify an existing resource pool and
# allocate LynxKite to it.
# export RESOURCE_POOL=

# Specify how much memory is available for LynxKite on a single worker machine.
# Ignored for local setups, use KITE_MASTER_MEMORY_MB for that case.
export EXECUTOR_MEMORY=1g

# Specify the number of executors. For standalone cluster it defaults to as many as possible.
# For a YARN setup, this options is mandatory.
# export NUM_EXECUTORS=5

# Specify the number of cores per executor LynxKite should use.
export NUM_CORES_PER_EXECUTOR=4

# Specify how much memory is available for LynxKite on the master machine in megabytes.
# For local setups this also determines executor memory and EXECUTOR_MEMORY is
# ignored in that case.
export KITE_MASTER_MEMORY_MB=1024

# Specify the port for the LynxKite HTTP server to listen on. Must be >=1000.
export KITE_HTTP_PORT=2200

# Specify the HTTP port for the watchdog. If this is set, the startup script will start a watchdog
# as well which will automatically restart the LynxKite server if it detects any problem.
# export KITE_WATCHDOG_PORT=2202

# Uncomment this to start an internal watchdog thread inside LynxKite's
# driver JVM. This watchdog will kill LynxKite if health checks are
# failing continuously for the given amount of time.
# export KITE_INTERNAL_WATCHDOG_TIMEOUT_SECONDS=1200

# The LynxKite local temp directory is a local path that exists on all workers and the master and will
# be used for storing temporary Spark/Hadoop files. This directory can potentially use a lot of
# space, so if you have a small root filesystem and an extra large drive mounted somewhere then you
# need to point this to somewhere on the large drive. On the other hand performance of this drive has
# a significant effect on overall speed, so using an SSD is a nice option here.
export KITE_LOCAL_TMP=/tmp

# Configure the directory LynxKite uses for logging. Defaults to logs under the LynxKite
# installation directory if not specified.
# export KITE_LOG_DIR=

# The LynxKite extra JARS is a colon (:) delimited list of JAR files that should be loaded on the
# LynxKite CLASSPATH. (It will be loaded on the master and distributed to the workers.)

# - Some wildcards are supported, you can use /dir/*, but you cannot use /dir/*.jar.
# - Filenames have to be absolute paths.

# One typical use case is to configure additional JDBC drivers. To do that, all you need to do is to
# add the jar file here.
export KITE_EXTRA_JARS=

# You can enable an interactive Scala interpreter able to access LynxKite internals by using
# the below exports. You can access the interpreter by SSHing from the host running LynxKite as:
# ssh ${KITE_AMMONITE_USER}@localhost -p ${KITE_AMMONITE_PORT}
# and use KITE_AMMONITE_PASSWD as password.

# If you do this and do not trust all users who can SSH into this machine (the typical case!)
# then make sure to modify the file system permissions of .kiterc to be only readable by the
# user running LynxKite and change the password below.
# export KITE_AMMONITE_PORT=2203
# export KITE_AMMONITE_USER=lynx
# export KITE_AMMONITE_PASSWD=kite

# Options needed if you want to use authentication and HTTPS.

# Just use the following configurations with default values for a simple, fake certificate setup.

# ===========================================================
# Application secret used by Play! framework for various tasks, such as signing cookies and
# encryption. Setting this to <random> will regenerate a secret key at each restart.
# More details can be found
# here (https://playframework.com/documentation/latest/ApplicationSecret).
# export KITE_APPLICATION_SECRET='<random>'

# Specify the port for the LynxKite HTTPS server to listen on. Must be >=1000.
# export KITE_HTTPS_PORT=2201

# Set the keystore file and password with the HTTPS keys. Use the default values for a fake HTTPS
# certificate. If you have your own intranet CA or a wildcard certificate, you can generate a
# certificate for LynxKite that the browsers can validate. Follow the instructions at
# Apache Tomcat (http://tomcat.apache.org/tomcat-6.0-doc/ssl-howto.html) for creating a keystore file.
# export KITE_HTTPS_KEYSTORE=${KITE_DEPLOYMENT_CONFIG_DIR}/localhost.self-signed.cert
# export KITE_HTTPS_KEYSTORE_PWD=keystore-password
# ===========================================================

# The LynxKite Google client secret is only needed for Google Authenticator. Ask the Lynx R&D
# team for further instructions if you think you need this feature.
# export KITE_GOOGLE_CLIENT_SECRET='???'

# Use the following configurations to set up LDAP authentication.

# ===========================================================
# The URL of the LDAP server, e.g. ldap://localhost:389.
# export LDAP_URL=

# The authentication method, e.g. simple or DIGEST-MD5 as explained in
# the Java LDAP documentation (http://docs.oracle.com/javase/jndi/tutorial/ldap/security/index.html)
# and SASL documentation (http://docs.oracle.com/javase/jndi/tutorial/ldap/security/sasl.html).
# export LDAP_AUTHENTICATION=simple

# The template for the principal. It must contain the word <USERNAME> to be substituted with the
# username given at login, for example uid=<USERNAME>,ou=People,dc=example,dc=com or
# cn=<USERNAME>,ou=People,dc=example,dc=com. This is required so the user does not have to specify
# the full distinguished name on the web UI.
# export LDAP_PRINCIPAL_TEMPLATE=
# ===========================================================

# On a Kerberos-secured Hadoop cluster, set the KERBEROS_PRINCIPAL and KERBEROS_KEYTAB
# variables. The principal acts like a user name and the keytab file acts like a password.
# export KERBEROS_PRINCIPAL=
# export KERBEROS_KEYTAB=

# Uncomment the below lines to export LynxKite's Spark metrics into
# a Graphite-compatible monitoring system. You can use this together
# with tools/monitoring/restart_monitoring_master.sh.
# export GRAPHITE_MONITORING_HOST=$(hostname)
# export GRAPHITE_MONITORING_PORT=9109
