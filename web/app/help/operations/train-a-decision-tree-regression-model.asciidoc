### Train a decision tree regression model

Trains a decision tree regression model using the graph's vertex attributes.
The algorithm recursively partitions the feature space into two parts. The tree
predicts the same label for each bottommost (leaf) partition. Each binary
partitioning is chosen from a set of possible splits in order to maximize the
information gain at the corresponding tree node. For calculating the information
gain the variance of the nodes is used:
the information gain is the difference between the parent node impurity and the
weighted sum of the two child node impurities.
https://spark.apache.org/docs/latest/mllib-decision-tree.html#basic-algorithm[More information about the parameters.]
====
[[name]] Model name::
The model will be stored as a scalar attribute using this name.

[[label]] Label attribute::
The vertex attribute the model is trained to predict.

[[features]] Feature attributes::
The attributes the model learns to use for making predictions.

[[maxbins]] Maximum number of bins::
Number of bins used when discretizing continuous features.

[[maxdepth]] Maximum depth::
Maximum depth of the tree.

[[mininfogain]] Minimum information gain::
Minimum information gain for a split to be considered as a tree node.

[[minInstancesPerNode]] Minimum instances per node::
For a node to be split further, the split must improve at least this much
(in terms of information gain).

[[seed]] Seed::
Random seed.
