// To avoid repetition, add text here and include it in multiple places.
//
// Include syntax:
//   include::{g}[tag=my-tag]
//
// Note that there are no implicit newlines around the inclusion. This means you could
// (intentionally or not) include something as inline content.

tag::database-access[]
The database name is the JDBC connection string without the `jdbc:` prefix.
(For example `mysql://127.0.0.1/my_database?user=batman&password=alfred`.)
See <<jdbc-details>> for more details.
end::database-access[]

tag::database-import[]
[p-db]#Database#::
include::glossary.asciidoc[tag=database-access]

[p-table]#Table or view#::
Table to import from. This can be anything that can be put into the `SELECT * FROM table`
statement.

[p-columns]#Columns#::
The comma-separated list of columns to import.

[p-key]#Key column#::
This numerical column is used to partition the SQL query. The range from `min(key)` to `max(key)`
will be split into a sub-range for each Spark worker, so they can each query a part of the data in
parallel.
end::database-import[]

tag::database-export[]
[p-db]#Database#::
The database to write to.
+
include::{g}[tag=database-access]

[p-table]#Table#::
The table to create in the database.

[p-attrs]#Attributes#::
Attributes to export.

[p-delete]#Overwrite table if it exists#::
If disabled, the operation will fail if the target table already existis.
If enabled, all data in the table will be deleted before inserting the new data. Be careful!
end::database-export[]

tag::file-export[]
There are two ways to access the exported data:

 - Set _Destination path_ to `<auto>`. A download link will be generated.
   This works even for large files as long as they fit on your hard drive.
 - Set _Destination path_ to a distributed file system path that you can access. This allows
   you to access the exported data using the standard tools for the file system. A download link
   will still be provided, but the standard tools can allow for higher throughput access.
end::file-export[]

tag::csv-import[]
[p-files]#Files#::
Upload a file using the button on the right, or specify the path to an existing file set.
Wildcard (`+foo/*.csv+`) and glob (`+foo/{bar,baz}.csv+`) patterns are accepted.
+
The file must be specified as a <<prefixed-paths, prefixed path>>, such as `+MY_ROOT$dir/*.csv+`.

[p-header]#Header#::
The list of column names. This parameter serves two purposes:
+
 - Each column specified will be imported as an attribute.
 - If this line is found in the CSV, it will be ignored.
+
When left as `<read first line>`, the header is read automatically from the file.

[p-delimiter]#Delimiter#::
The column delimiter in the CSV. Typical values are `,` (comma), `;` (semicolon), `\t` (tab).

[p-omitted]#(optional) Comma separated list of columns to omit#::
If you don't want to read all columns of your CSV, list here the name of columns you don't need.

[p-filter]#(optional) Filtering expression#::
A JavaScript expression can be provided here to restrict the import to lines that match a
condition. For example `id != ''` would ignore lines where the `id` column is empty.

[p-allow_corrupt_lines]#Tolerate ill-formed lines#::
When set to `no`, the import process will stop with an error as soon as it encounters
a line that does not match the header. When set to `yes`, erroneous lines will be
silently skipped.
end::csv-import[]

tag::table-import[]
[p-table]#Table#::
The table to import from.
end::table-import[]

tag::import-box[]
[p-imported_columns]#Columns to import#::
The columns to import. Leave empty to import all columns.

[p-limit]#Limit#::
Number of rows to import at the most. Leave empty to import all rows.

[p-sql]#SQL#::
Spark SQL query to execute before writing the imported data to storage. The input table
can be referred to as `this` in the query. For example:
`SELECT * FROM this WHERE date = '2019-01-01'`

[p-imported_table]#Table GUID#::
Click this button to actually kick off the import. You can click it again later to repeat the
import. (Useful if the source data has changed.)
end::import-box[]

tag::random-seed[]
=====
LynxKite operations are typically deterministic. If you re-run an operation with
the same random seed, you will get the same results as before. To get a truly independent random
re-run, make sure you choose a different random seed.

The default value for random seed parameters is randomly picked, so only very
rarely do you need to give random seeds any thought.
=====
end::random-seed[]

tag::random-attribute[]
Generates a new random numeric attribute with the specified distribution, which can be either
(1) a Standard Normal (i.e., Gaussian) distribution with a mean of 0 and a standard deviation of 1, or (2)
a Standard Uniform distribution where values fall between 0 and 1.

====
[p-name]#Attribute name#::
The new attribute will be created under this name.

[p-dist]#Distribution#::
The desired random distribution.

[p-seed]#Seed#::
The random seed.
+
include::{g}[tag=random-seed]
====
end::random-attribute[]

tag::weighted-aggregators[]
[p-add_suffix]#Add suffixes to attribute names#::
Choose whether to add a suffix to the resulting aggregated variable.
(e.g. `income_weighted_sum_by_size` vs `income`.)
A suffix is required when you take multiple aggregations.

The available weighted aggregators are:

 * For `number` attributes:
 ** `by_max_weight` (picks a value for which the corresponding weight value is maximal)
 ** `by_min_weight` (picks a value for which the corresponding weight value is minimal)
 ** `weighted_average`
 ** `weighted_sum`

 * For other attributes:
 ** `by_max_weight` (picks a value for which the corresponding weight value is maximal)
 ** `by_min_weight` (picks a value for which the corresponding weight value is minimal)

end::weighted-aggregators[]

tag::global-aggregators[]
[p-add_suffix]#Add suffixes to attribute names#::
Choose whether to add a suffix to the resulting aggregated variable.
(e.g. `income_average` vs `income`.)
A suffix is required when you take multiple aggregations.

The available aggregators are:

 * For `number` attributes:
 ** `average`
 ** `count` (number of cases where the attribute is defined)
 ** `first` (arbitrarily picks a value)
 ** `max`
 ** `min`
 ** `std_deviation` (standard deviation)
 ** `sum`

 * For `Vector[Double]` attributes:
 ** `concatenate` (the vectors concatenated in arbitrary order)
 ** `count` (number of cases where the attribute is defined)
 ** `count_distinct` (the number of distinct values)
 ** `count_most_common` (the number of occurrences of the most common value)
 ** `elementwise_average` (a vector of the averages for each element)
 ** `elementwise_max` (a vector of the maximum for each element)
 ** `elementwise_min` (a vector of the minimum for each element)
 ** `elementwise_std_deviation` (a vector of the standard deviation for each element)
 ** `elementwise_sum` (a vector of the sums for each element)
 ** `first` (arbitrarily picks a value)
 ** `most_common`

 * For other attributes:
 ** `count` (number of cases where the attribute is defined)
 ** `first` (arbitrarily picks a value)
end::global-aggregators[]

tag::local-aggregators[]
[p-add_suffix]#Add suffixes to attribute names#::
Choose whether to add a suffix to the resulting aggregated variable.
(e.g. `income_median` vs `income`.)
A suffix is required when you take multiple aggregations.

The available aggregators are:

 * For `number` attributes:
 ** `average`
 ** `count_distinct` (the number of distinct values)
 ** `count_most_common` (the number of occurrences of the most common value)
 ** `count` (number of cases where the attribute is defined)
 ** `first` (arbitrarily picks a value)
 ** `max`
 ** `median`
 ** `min`
 ** `most_common`
 ** `set` (all the unique values, as a `Set` attribute)
 ** `std_deviation` (standard deviation)
 ** `sum`
 ** `vector` (all the values, as a `Vector` attribute)

 * For `String` attributes:
 ** `count_distinct` (the number of distinct values)
 ** `count_most_common` (the number of occurrences of the most common value)
 ** `count` (number of cases where the attribute is defined)
 ** `first` (arbitrarily picks a value)
 ** `majority_100` (the value that 100% agree on, or empty string)
 ** `majority_50` (the value that 50% agree on, or empty string)
 ** `most_common`
 ** `set` (all the unique values, as a `Set` attribute)
 ** `vector` (all the values, as a `Vector` attribute)

 * For `Vector[Double]` attributes:
 ** `concatenate` (the vectors concatenated in arbitrary order)
 ** `count` (number of cases where the attribute is defined)
 ** `count_distinct` (the number of distinct values)
 ** `count_most_common` (the number of occurrences of the most common value)
 ** `elementwise_average` (a vector of the averages for each element)
 ** `elementwise_max` (a vector of the maximum for each element)
 ** `elementwise_min` (a vector of the minimum for each element)
 ** `elementwise_std_deviation` (a vector of the standard deviation for each element)
 ** `elementwise_sum` (a vector of the sums for each element)
 ** `first` (arbitrarily picks a value)
 ** `most_common`

 * For other attributes:
 ** `count_distinct` (the number of distinct values)
 ** `count_most_common` (the number of occurrences of the most common value)
 ** `count` (number of cases where the attribute is defined)
 ** `most_common`
 ** `set` (all the unique values, as a `Set` attribute)
end::local-aggregators[]

tag::sql-box[]

See the <<SQL syntax>> section for more.

The following tables are available for SQL access for graph inputs:

 - All the vertex attributes can be accessed in the `vertices` table.
+
Example: `select count(*) from {maybe-tick}{prefix}vertices{maybe-tick} where age < 30`

 - All the edge attributes can be accessed in the `edge_attributes` table.
+
Example: `select max(weight) from {maybe-tick}{prefix}edge_attributes{maybe-tick}`
+
You can not query the `edge_attributes` table if there are no edge attributes, even if the edges
themselves are defined.

 - All the graph attributes can be accessed in the `graph_attributes` table.
+
Example: `select {backtick}!vertex_count{backtick} from {maybe-tick}{prefix}graph_attributes{maybe-tick}`

 - All the edge and vertex attributes can be accessed in the `edges` table. Each row of this
table represents an edge. The attributes of the edge are prefixed with `edge_`, while the attributes
of the source and destination vertices are prefixed with `src_` and `dst_` respectively.
+
Example:
`select max(edge_weight) from {maybe-tick}{prefix}edges{maybe-tick} where src_age < dst_age`

 - The `belongs_to` table is defined for each segmentation of a graph or a segmentation. It
contains the vertex attributes for the connected pairs of base and segmentation vertices prefixed
with `base_` and `segment_` respectively.
+
Examples:

 * `select count(*) from {backtick}{prefix}communities.belongs_to{backtick} group by segment_id`
 * `select base_name from {backtick}{prefix}communities.belongs_to{backtick} where segment_name =
 "COOKING"`

Backticks (`{backtick}`) are used for escaping table and column names with special characters.

For single-input SQL boxes the `edges`, `vertices`, etc. tables can be accessed with or without the
input name prefix.

You can browse the list of available tables and columns by clicking on the
+++<label class="btn btn-primary">Tables ‚èµ</label>+++
button.

====
[p-summary]#Summary#::
This summary will be displayed below the box in the workspace. Distinguishing SQL boxes this way
can make the workspace easier to understand.

[p-input_names]#Input names#::
Comma-separated list of names used to refer to the inputs of the box.
+
For example, you can set it to `accounts` (for a single-input SQL box) and then write `select
count(*) from accounts` as the query.

[p-sql]#SQL query#::
The query. Press Ctrl-Enter to save your changes while staying in the editor.

[p-persist]#Persist result#::
If enabled, the output table will be saved to disk once it is calculated. If disabled, the query
will be re-executed each time its output is used. Persistence can improve performance at the cost of
disk space.
====
end::sql-box[]

tag::full-lk-path[]
A full path in the LynxKite directory system has the following form:
`top_folder/subfolder_1/subfolder_2/.../subfolder_n/name` +
Keep in mind that there is no leading slash at the beginning of the path.
end::full-lk-path[]

tag::external-computation-box[]
This box represents computation outside of LynxKite. See the `@external` decorator in the Python
API.

====
[p-snapshot_prefix]#Snapshot prefix#::
The external computation will save the results as a snapshot. This is the prefix of the name of that
snapshot.
====
end::external-computation-box[]

tag::save-mode-options[]
[p-save_mode]#Save mode#::
The following modes can be used: "error if exists", "overwrite", "append", "ignore". In
the last case already existing data will not be modified.
end::save-mode-options[]
