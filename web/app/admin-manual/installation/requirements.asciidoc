## Requirements

### Java version

You need Java 8 on the system.

### Write permission

You need write permission to the directory configured as `KITE_DATA_DIR`. On HDFS a home directory
is also required for the user that starts LynxKite. Example commands to create these directories:

- `sudo -u hdfs hadoop fs -mkdir hdfs://$NAMENODE:8020/kite_data`
- `sudo -u hdfs hadoop fs -mkdir hdfs://$NAMENODE:8020/user/$USER`
- `sudo -u hdfs hadoop fs -chown $USER hdfs://$NAMENODE:8020/kite_data`
- `sudo -u hdfs hadoop fs -chown $USER hdfs://$NAMENODE:8020/user/$USER`

### Port collision

By default LynxKite runs on port 2200. If this is used by another process, move LynxKite to a
different port (by changing the `KITE_HTTP_PORT` setting in `.kiterc`).

### YARN settings

[[yarn-memory-limit]]
#### YARN memory limit

Set the executor memory (`EXECUTOR_MEMORY`) lower than the YARN NodeManager memory limit defined
with the `yarn.nodemanager.resource.memory-mb` and `yarn.scheduler.maximum-allocation-mb` settings
in the YARN configurations.

#### Smart YARN memory monitor

If allowed by the YARN administrator, set
`yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled` to `true` in the
YARN configuration. This will prevent the YARN nodemanager from incorrectly including
shared memory regions in the total physical memory used by Spark executors. Not setting this
flag may result in the node manager unjustly but mercilessly shutting down the executor.


[[the-32-gb-rule]]
### The 32 GB rule

The Java Virtual Machine can be configured to use practically any amount of RAM on a 64 bit system.
However its efficiency breaks down after 32 GB. Therefore a JVM with 40GB RAM is actually worse
than a JVM with 32 GB RAM. For that reason it is not recommended to set the `EXECUTOR_MEMORY` above
32 GB. It makes more sense to create multiple executors with less amount of RAM per executor.


