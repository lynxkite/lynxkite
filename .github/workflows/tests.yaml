name: Tests
on: pull_request
jobs:
  backend-test-spark:
    name: Backend test with Spark
    runs-on: ubuntu-latest
    steps:
    - name: Check out code
      uses: actions/checkout@v2
    - name: Cache node modules
      uses: actions/cache@v2
      with:
        path: ~/.npm
        key: ${{ runner.os }}-npm-${{ hashFiles('**/package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-npm
    - name: Cache SBT stuff
      uses: actions/cache@v2
      with:
        path: ~/.ivy2
        key: ${{ runner.os }}-ivy2-${{ hashFiles('**/build.sbt') }}
        restore-keys: |
          ${{ runner.os }}-ivy2
    - name: Cache Go stuff
      uses: actions/cache@v2
      with:
        path: ~/go
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go
    - name: Cache Spark
      uses: actions/cache@v2
      with:
        path: ~/spark
        key: ${{ runner.os }}-spark-${{ hashFiles('**/SPARK_VERSION') }}
        restore-keys: |
          ${{ runner.os }}-spark
    - name: Cache Conda
      uses: actions/cache@v2
      with:
        path: ~/.conda
        key: ${{ runner.os }}-conda-${{ hashFiles('**/install-dependencies.sh') }}
        restore-keys: |
          ${{ runner.os }}-conda
    - name: Install dependencies
      uses: conda-incubator/setup-miniconda@v2
      with:
        environment-file: conda-env.yml
        use-only-tar-bz2: true # For caching.
    - name: Test backend with Spark
      run: make #backend-test-spark
